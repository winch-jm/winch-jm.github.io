---
---

@string{aps = {American Physical Society,}}


@article{winchell2024scalefex,
  abbr={iScience},
  title={A Highly-Efficient, Scalable Pipeline for Fixed Feature Extraction from Large-Scale High-Content Imaging Screens},
  author={Comolet, Gabriel and Bose, Neeloy and Winchell, Jeff and Duren-Lubanski, Alyssa and Rusielewicz, Tom and Goldberg, Jordan and Horn, Grayson and Paull, Daniel and Migliori, Bianca},
  abstract={Applying artificial intelligence (AI) to image-based morphological profiling cells offers significant potential for identifying disease states and drug responses in high-content imaging (HCI) screens. When differences between populations (e.g., healthy vs. diseased) are unknown or imperceptible to the human eye, large-scale HCI screens are essential, providing numerous replicates to build reliable models and accounting for confounding factors like donor and intra-experimental variations. As screen sizes grow, so does the challenge of analyzing high-dimensional datasets in an efficient way while preserving interpretable features and predictive power. Here, we introduce ScaleFExâ„ , a memory-efficient, open-source Python pipeline that extracts biologically meaningful features from HCI datasets using minimal computational resources or scalable cloud infrastructure. ScaleFEx can be used together with AI models to successfully identify phenotypic shifts in drug-treated cells and rank interpretable features, and is applicable to public datasets, highlighting its potential to accelerate the discovery of disease-associated phenotypes and new therapeutics.},
  year={2024},
  html={https://doi.org/10.1016/j.isci.2024.111434},
  code={https://github.com/NYSCF/ScaleFEx},
  selected={true},
  journal={iScience},
  publisher={Elsevier}
}

@article{winchell2023foca,
  abbr={SLAS Discovery},
  title={FocA: A deep learning tool for reliable, near-real-time imaging focus analysis in automated cell assay pipelines},
  author={Winchell, Jeff and Comolet, Gabriel and Buckley-Herd, Geoff and Hutson, Dillion and Bose, Neeloy and Paull, Daniel and Migliori, Bianca},
  abstract={The increasing use of automation in cellular assays and cell culture presents significant opportunities to enhance the scale and throughput of imaging assays, but to do so, reliable data quality and consistency are critical. Realizing the full potential of automation will thus require the design of robust analysis pipelines that span the entire workflow in question. Here we present FocA, a deep learning tool that, in near real-time, identifies in-focus and out-of-focus images generated on a fully automated cell biology research platform, the NYSCF Global Stem Cell Array (Registered Trademark). The tool is trained on small patches of downsampled images to maximize computational efficiency without compromising accuracy, and optimized to make sure no sub-quality images are stored and used in downstream analyses. The tool automatically generates balanced and maximally diverse training sets to avoid bias. The resulting model correctly identifies 100% of out-of-focus and 98% of in-focus images in under 4 seconds per 96-well plate, and achieves this result even in heavily downsampled data (~30 times smaller than native resolution). Integrating the tool into automated workflows minimizes the need for human verification as well as the collection and usage of low-quality data. FocA thus offers a solution to ensure reliable image data hygiene and improve the efficiency of automated imaging workflows using minimal computational resources.},
  year={2023},
  html={https://doi.org/10.1016/j.slasd.2023.08.004},
  code={https://github.com/NYSCF/foca_release},
  selected={true},
  altmetric={true},
  journal={SLAS Discovery},
  publisher={Elsevier}
}

@article{moyer2021funcprot,
  abbr={arXiv},
  title={Functional Protein Structure Annotation Using a Deep Convolutional Generative Adversarial Network},
  author={Moyer, Ethan and Winchell, Jeff and Isozaki, Isamu and Alparslan, Yigit and Halac, Mali and Kim, Edward},
  abstract={Identifying novel functional protein structures is at the heart of molecular engineering and molecular biology, requiring an often computationally exhaustive search. We introduce the use of a Deep Convolutional Generative Adversarial Network (DCGAN) to classify protein structures based on their functionality by encoding each sample in a grid object structure using three features in each object: the generic atom type, the position atom type, and its occupancy relative to a given atom. We train DCGAN on 3-dimensional (3D) decoy and native protein structures in order to generate and discriminate 3D protein structures. At the end of our training, loss converges to a local minimum and our DCGAN can annotate functional proteins robustly against adversarial protein samples. In the future we hope to extend the novel structures we found from the generator in our DCGAN with more samples to explore more granular functionality with varying functions. We hope that our effort will advance the field of protein structure prediction.},
  year={2021},
  html={https://arxiv.org/abs/2104.08969},
  journal={arXiv}
}